
# Model/Provider Matchups


It's important that we select providers that provide the model in the same precision as which it was released (e.g. if a model was released in bf16, don't use an fp8 precision version of it).
OpenRouter makes this information available: https://openrouter.ai/meta-llama/llama-3.3-70b-instruct/providers
We want to select a provider for each model that prvov

- Qwen 2.5 72B Instruct: DeepInfra (Offers in original bf16 and seems to pass my tests in openrouter_test.py)
- Meta-Llama 3.3 70B Instruct: Novita (Offers in original bf16 and seems to pass my tests; Hyperbolic failed.)
- 